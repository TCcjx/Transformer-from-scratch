# 手搓实现GPT2
## Only Decoder 的 文本生成架构
### 1.训练数据集使用了一个很小的销售教材数据集 (data/sales_textboo.txt)
### 2.main.py: 网络架构 和 训练函数实现过程：-> 生成模型训练权重文件
### 3.step_by_step.ipynb过程是transformer架构的理解推理过程，清晰的说明了整个文本生成的推理过程
### 4.test.py：加载训练权重,实现可控长度的文本续写。
### model训练权重由于太大，所以不上传了。
